{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic, Matern, WhiteKernel, RBF\n",
    "from sklearn.gaussian_process.kernels import Sum\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set this value to true if hyperparameter tuning is complete and the test set should be loaded and predicted on\n",
    "OUTPUT_TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the training and validation datasets\n",
    "X_train = pd.read_csv(\"../data/cleaned/training.csv\")\n",
    "y_train = pd.read_csv(\"../data/cleaned/training_labels.csv\")\n",
    "X_val = pd.read_csv(\"../data/cleaned/validation.csv\")\n",
    "y_val = pd.read_csv(\"../data/cleaned/validation_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some columns headers contain '[' or ']' which are not compatable with sklearn. They are change to '(' and ')' respectively.\n",
    "columns = X_train.columns\n",
    "for col in columns:\n",
    "    if '[' in col or ']' in col:\n",
    "        old_name = col\n",
    "        col = col.replace('[', '(')\n",
    "        col = col.replace(']', ')')\n",
    "        \n",
    "        X_train = X_train.rename(columns={old_name:col})\n",
    "        X_val = X_val.rename(columns={old_name:col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting of the training set into a vedrification and training set with a 90/10 split. This verification set is used for optuna hyperparameter tuning.\n",
    "X_train, X_verif, y_train, y_verif = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset the indicies after splitting the dataset\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_verif = X_verif.reset_index(drop=True)\n",
    "y_verif = y_verif.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the guassian process search space for Optuna.\n",
    "def define_kernel(trial):\n",
    "    kernels = []\n",
    "    n_kernels = trial.suggest_int('n_kernels', 1, 3) #Number of simple kernels used to create the final kernel\n",
    "    for i in range(n_kernels):\n",
    "        kernel_type = trial.suggest_categorical(f'kernel_type_{i}', [\"Matern\", \"RationalQuadratic\"]) #Select a type of simple kernel\n",
    "\n",
    "        #Depending on the kernel type selected, certain metrics need to specificed, each of those metrics is selected below by optuna as the tuning takes place\n",
    "        if kernel_type == 'RationalQuadratic':\n",
    "            quad_params = {\n",
    "                'length_scale': trial.suggest_float(f'RationalQuadratic_{i}_length_scale', 1e-1, 1e5),\n",
    "                'alpha': trial.suggest_float(f'RationalQuadratic_{i}_alpha', 1e-1, 1e5)\n",
    "            }   \n",
    "            kernel = RationalQuadratic(length_scale=quad_params['length_scale'], alpha=quad_params['alpha'], length_scale_bounds=(1e-8,1e8))\n",
    "        elif kernel_type == 'Matern':\n",
    "            matern_params = {\n",
    "                'length_scale': trial.suggest_float(f'Matern_{i}_length_scale', 1e-1, 1e5),\n",
    "                'nu': trial.suggest_float(f'Matern_{i}_nu', 0.5, 5)\n",
    "            }\n",
    "            kernel = Matern(length_scale=matern_params['length_scale'], nu=matern_params['nu'], length_scale_bounds=(1e-8,1e8))\n",
    "        else:\n",
    "            print(\"WRONG KERNEL NAME FOR:\", kernel_type)\n",
    "            TypeError\n",
    "        kernels.append(kernel)\n",
    "\n",
    "    white_noise_params = {\n",
    "                'noise_level': trial.suggest_float(f'WhiteKernel_{n_kernels}_noise_level', 1e-5, 1e5),\n",
    "            }\n",
    "    #kernel = WhiteKernel(noise_level=white_noise_params['noise_level'])\n",
    "    #kernels.append(kernel)\n",
    "    if n_kernels == 1:\n",
    "        combined_kernel = kernels[0]\n",
    "    else:\n",
    "        combined_kernel = Sum(kernels[0], kernels[1])\n",
    "        for j in range(1, n_kernels-1):\n",
    "            combined_kernel = Sum(combined_kernel, kernels[j+1])\n",
    "    return combined_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Define the objective function\"\"\"\n",
    "    kernel = define_kernel(trial)\n",
    "    params = {\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 1e3, log=True),\n",
    "        'n_restarts_optimizer': trial.suggest_int('n_restarts_optimizer', 0, 10),\n",
    "    }\n",
    "\n",
    "    params[\"kernel\"] = kernel\n",
    "    print(params)\n",
    "    # Fit the model\n",
    "    optuna_model = GaussianProcessRegressor(**params)\n",
    "    \n",
    "    batch_size = 500\n",
    "\n",
    "    # Take a random sample of the DataFrame\n",
    "    X_train_sampled = X_train.sample(n=batch_size)\n",
    "\n",
    "    # Access the indexes of the sampled rows\n",
    "    sampled_indexes = X_train_sampled.index\n",
    "    y_train_sampled = y_train.loc[sampled_indexes]\n",
    "\n",
    "    optuna_model.fit(X_train_sampled, y_train_sampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    verif_pred = optuna_model.predict(X_verif)\n",
    "    verif_loss = mean_absolute_percentage_error(y_verif,verif_pred)*100\n",
    "    verif_error = mean_squared_error(y_verif,verif_pred,squared=False)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    error = verif_loss + verif_error\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-19 17:22:42,257]\u001b[0m A new study created in memory with name: no-name-67ce1b1a-c429-4e04-ba6b-7562cf0fa2ac\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.4322961695854962, 'n_restarts_optimizer': 10, 'kernel': RationalQuadratic(alpha=2.77e+04, length_scale=3.85e+04) + Matern(length_scale=8.92e+04, nu=1.73) + Matern(length_scale=4.56e+03, nu=4.55)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__length_scale is close to the specified lower bound 1e-08. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-12-19 17:26:33,190]\u001b[0m Trial 0 finished with value: 48.51528888534959 and parameters: {'n_kernels': 3, 'kernel_type_0': 'RationalQuadratic', 'RationalQuadratic_0_length_scale': 38541.8416897705, 'RationalQuadratic_0_alpha': 27689.71642443232, 'kernel_type_1': 'Matern', 'Matern_1_length_scale': 89153.08672572863, 'Matern_1_nu': 1.726037581968306, 'kernel_type_2': 'Matern', 'Matern_2_length_scale': 4557.4908305312, 'Matern_2_nu': 4.551686402008937, 'WhiteKernel_3_noise_level': 46271.995898288056, 'alpha': 0.4322961695854962, 'n_restarts_optimizer': 10}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.2212138429940311, 'n_restarts_optimizer': 1, 'kernel': Matern(length_scale=7.86e+04, nu=0.848) + RationalQuadratic(alpha=7.77e+04, length_scale=8.73e+04)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-08. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-12-19 17:27:00,680]\u001b[0m Trial 1 finished with value: 49.66094240423003 and parameters: {'n_kernels': 2, 'kernel_type_0': 'Matern', 'Matern_0_length_scale': 78623.28077857281, 'Matern_0_nu': 0.8476520284471216, 'kernel_type_1': 'RationalQuadratic', 'RationalQuadratic_1_length_scale': 87259.83313914941, 'RationalQuadratic_1_alpha': 77720.5492153229, 'WhiteKernel_2_noise_level': 39932.49011801804, 'alpha': 1.2212138429940311, 'n_restarts_optimizer': 1}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 432.9535822424795, 'n_restarts_optimizer': 7, 'kernel': Matern(length_scale=3.42e+04, nu=1.85) + RationalQuadratic(alpha=8.57e+04, length_scale=6.71e+04)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified upper bound 100000000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-12-19 17:27:51,430]\u001b[0m Trial 2 finished with value: 58.7329045690527 and parameters: {'n_kernels': 2, 'kernel_type_0': 'Matern', 'Matern_0_length_scale': 34230.40350996027, 'Matern_0_nu': 1.8468250246883953, 'kernel_type_1': 'RationalQuadratic', 'RationalQuadratic_1_length_scale': 67058.65748434357, 'RationalQuadratic_1_alpha': 85652.03602721292, 'WhiteKernel_2_noise_level': 30357.123142221968, 'alpha': 432.9535822424795, 'n_restarts_optimizer': 7}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 200.34620398260066, 'n_restarts_optimizer': 3, 'kernel': RationalQuadratic(alpha=1.62e+04, length_scale=8.47e+04) + Matern(length_scale=9.45e+04, nu=1.86)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__length_scale is close to the specified upper bound 100000000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-12-19 17:28:18,009]\u001b[0m Trial 3 finished with value: 52.221927661118436 and parameters: {'n_kernels': 2, 'kernel_type_0': 'RationalQuadratic', 'RationalQuadratic_0_length_scale': 84674.85793800294, 'RationalQuadratic_0_alpha': 16233.422477122365, 'kernel_type_1': 'Matern', 'Matern_1_length_scale': 94544.62050641587, 'Matern_1_nu': 1.8642852059291561, 'WhiteKernel_2_noise_level': 92325.1131189338, 'alpha': 200.34620398260066, 'n_restarts_optimizer': 3}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 351.94670525145904, 'n_restarts_optimizer': 0, 'kernel': RationalQuadratic(alpha=6.02e+04, length_scale=9.36e+04)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-19 17:28:19,080]\u001b[0m Trial 4 finished with value: 65.3329260350107 and parameters: {'n_kernels': 1, 'kernel_type_0': 'RationalQuadratic', 'RationalQuadratic_0_length_scale': 93629.10224075186, 'RationalQuadratic_0_alpha': 60222.53501614783, 'WhiteKernel_1_noise_level': 21427.438994376975, 'alpha': 351.94670525145904, 'n_restarts_optimizer': 0}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.18991128718631514, 'n_restarts_optimizer': 2, 'kernel': Matern(length_scale=3.46e+04, nu=1.62) + Matern(length_scale=6.73e+04, nu=0.9)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-19 17:29:06,635]\u001b[0m Trial 5 finished with value: 50.20416917388933 and parameters: {'n_kernels': 2, 'kernel_type_0': 'Matern', 'Matern_0_length_scale': 34584.14764636267, 'Matern_0_nu': 1.6175443344533544, 'kernel_type_1': 'Matern', 'Matern_1_length_scale': 67288.39008079149, 'Matern_1_nu': 0.8998589617510898, 'WhiteKernel_2_noise_level': 3225.1954524307066, 'alpha': 0.18991128718631514, 'n_restarts_optimizer': 2}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 80.12896644067072, 'n_restarts_optimizer': 2, 'kernel': RationalQuadratic(alpha=7.35e+04, length_scale=7.05e+04) + Matern(length_scale=8.54e+04, nu=2.38) + RationalQuadratic(alpha=9.12e+04, length_scale=5.25e+03)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-19 17:29:27,379]\u001b[0m Trial 6 finished with value: 49.96794186850515 and parameters: {'n_kernels': 3, 'kernel_type_0': 'RationalQuadratic', 'RationalQuadratic_0_length_scale': 70532.00430542821, 'RationalQuadratic_0_alpha': 73514.79265722145, 'kernel_type_1': 'Matern', 'Matern_1_length_scale': 85401.23362900731, 'Matern_1_nu': 2.376469385421698, 'kernel_type_2': 'RationalQuadratic', 'RationalQuadratic_2_length_scale': 5248.631501571996, 'RationalQuadratic_2_alpha': 91234.62381813877, 'WhiteKernel_3_noise_level': 45798.61297106272, 'alpha': 80.12896644067072, 'n_restarts_optimizer': 2}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 33.86422299719959, 'n_restarts_optimizer': 8, 'kernel': Matern(length_scale=1.44e+04, nu=2.43)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified upper bound 100000000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-12-19 17:30:08,900]\u001b[0m Trial 7 finished with value: 49.95175673570424 and parameters: {'n_kernels': 1, 'kernel_type_0': 'Matern', 'Matern_0_length_scale': 14425.390626538121, 'Matern_0_nu': 2.4327242702023724, 'WhiteKernel_1_noise_level': 7772.49140687531, 'alpha': 33.86422299719959, 'n_restarts_optimizer': 8}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.004744966594095622, 'n_restarts_optimizer': 5, 'kernel': Matern(length_scale=4.65e+04, nu=4.75)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-19 17:30:53,392]\u001b[0m Trial 8 finished with value: 94.42001726488158 and parameters: {'n_kernels': 1, 'kernel_type_0': 'Matern', 'Matern_0_length_scale': 46480.785360740214, 'Matern_0_nu': 4.7511895181824215, 'WhiteKernel_1_noise_level': 24284.823852786227, 'alpha': 0.004744966594095622, 'n_restarts_optimizer': 5}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.003906363892735846, 'n_restarts_optimizer': 9, 'kernel': Matern(length_scale=1.6e+03, nu=0.724) + Matern(length_scale=6.5e+04, nu=0.675) + Matern(length_scale=6.86e+04, nu=4.51)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-19 17:34:55,258]\u001b[0m Trial 9 finished with value: 49.707179496745326 and parameters: {'n_kernels': 3, 'kernel_type_0': 'Matern', 'Matern_0_length_scale': 1601.5620475704468, 'Matern_0_nu': 0.7235582015812488, 'kernel_type_1': 'Matern', 'Matern_1_length_scale': 64980.65706703034, 'Matern_1_nu': 0.675053624731113, 'kernel_type_2': 'Matern', 'Matern_2_length_scale': 68644.39769146984, 'Matern_2_nu': 4.508445511382413, 'WhiteKernel_3_noise_level': 98282.87916777482, 'alpha': 0.003906363892735846, 'n_restarts_optimizer': 9}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.22116995682972637, 'n_restarts_optimizer': 10, 'kernel': RationalQuadratic(alpha=1.56e+04, length_scale=1.55e+04) + Matern(length_scale=9.35e+03, nu=4.6) + Matern(length_scale=1.35e+03, nu=0.845)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__length_scale is close to the specified lower bound 1e-08. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-12-19 17:39:46,054]\u001b[0m Trial 10 finished with value: 49.849223873809926 and parameters: {'n_kernels': 3, 'kernel_type_0': 'RationalQuadratic', 'RationalQuadratic_0_length_scale': 15487.572251159268, 'RationalQuadratic_0_alpha': 15570.834430916977, 'kernel_type_1': 'Matern', 'Matern_1_length_scale': 9352.770330805964, 'Matern_1_nu': 4.595014617766851, 'kernel_type_2': 'Matern', 'Matern_2_length_scale': 1349.555467320628, 'Matern_2_nu': 0.8451234384756727, 'WhiteKernel_3_noise_level': 7781.337379391334, 'alpha': 0.22116995682972637, 'n_restarts_optimizer': 10}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 3.7897877541987146, 'n_restarts_optimizer': 6, 'kernel': RationalQuadratic(alpha=3.7e+04, length_scale=3.03e+04) + RationalQuadratic(alpha=3.61e+04, length_scale=9.15e+04)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-19 17:40:05,218]\u001b[0m Trial 11 finished with value: 50.183610507958136 and parameters: {'n_kernels': 2, 'kernel_type_0': 'RationalQuadratic', 'RationalQuadratic_0_length_scale': 30254.812520691667, 'RationalQuadratic_0_alpha': 37030.85197132474, 'kernel_type_1': 'RationalQuadratic', 'RationalQuadratic_1_length_scale': 91480.94832868088, 'RationalQuadratic_1_alpha': 36116.768980955094, 'WhiteKernel_2_noise_level': 63351.51772213593, 'alpha': 3.7897877541987146, 'n_restarts_optimizer': 6}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 2.6184804419583445, 'n_restarts_optimizer': 4, 'kernel': Matern(length_scale=9.49e+04, nu=3.89) + RationalQuadratic(alpha=8.74e+04, length_scale=1.11e+04) + Matern(length_scale=49.3, nu=4.83)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-08. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-12-19 17:42:00,288]\u001b[0m Trial 12 finished with value: 49.283208047356375 and parameters: {'n_kernels': 3, 'kernel_type_0': 'Matern', 'Matern_0_length_scale': 94855.67130518469, 'Matern_0_nu': 3.886649642109063, 'kernel_type_1': 'RationalQuadratic', 'RationalQuadratic_1_length_scale': 11062.646706963955, 'RationalQuadratic_1_alpha': 87415.13693201271, 'kernel_type_2': 'Matern', 'Matern_2_length_scale': 49.28091891940767, 'Matern_2_nu': 4.828696030250407, 'WhiteKernel_3_noise_level': 52684.50907147756, 'alpha': 2.6184804419583445, 'n_restarts_optimizer': 4}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.043436828348113465, 'n_restarts_optimizer': 5, 'kernel': RationalQuadratic(alpha=9.91e+04, length_scale=5.16e+04) + RationalQuadratic(alpha=1.71e+03, length_scale=1.7e+03) + Matern(length_scale=1.62e+03, nu=4.98)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__length_scale is close to the specified lower bound 1e-08. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-12-19 17:44:26,854]\u001b[0m Trial 13 finished with value: 49.40309645446377 and parameters: {'n_kernels': 3, 'kernel_type_0': 'RationalQuadratic', 'RationalQuadratic_0_length_scale': 51614.27872486621, 'RationalQuadratic_0_alpha': 99116.89550652742, 'kernel_type_1': 'RationalQuadratic', 'RationalQuadratic_1_length_scale': 1695.8276535698096, 'RationalQuadratic_1_alpha': 1705.3985083769367, 'kernel_type_2': 'Matern', 'Matern_2_length_scale': 1615.1718510629357, 'Matern_2_nu': 4.975657442157939, 'WhiteKernel_3_noise_level': 52047.16076033533, 'alpha': 0.043436828348113465, 'n_restarts_optimizer': 5}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 12.759563687141059, 'n_restarts_optimizer': 4, 'kernel': RationalQuadratic(alpha=1.61e+03, length_scale=4.34e+04) + RationalQuadratic(alpha=9.96e+04, length_scale=1.39e+04) + Matern(length_scale=2.52e+04, nu=3.56)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-12-19 17:45:08,893]\u001b[0m Trial 14 finished with value: 50.021647214439675 and parameters: {'n_kernels': 3, 'kernel_type_0': 'RationalQuadratic', 'RationalQuadratic_0_length_scale': 43420.711676517014, 'RationalQuadratic_0_alpha': 1614.407257312596, 'kernel_type_1': 'RationalQuadratic', 'RationalQuadratic_1_length_scale': 13878.73493023758, 'RationalQuadratic_1_alpha': 99575.18821537952, 'kernel_type_2': 'Matern', 'Matern_2_length_scale': 25214.190182964412, 'Matern_2_nu': 3.5647429398259365, 'WhiteKernel_3_noise_level': 50219.3012119731, 'alpha': 12.759563687141059, 'n_restarts_optimizer': 4}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.031062472346451615, 'n_restarts_optimizer': 7, 'kernel': Matern(length_scale=9.85e+04, nu=4.04) + Matern(length_scale=2.77e+04, nu=3.81) + Matern(length_scale=9.9e+04, nu=3.41)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:629: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "\u001b[32m[I 2023-12-19 17:49:35,723]\u001b[0m Trial 15 finished with value: 48.656037489654445 and parameters: {'n_kernels': 3, 'kernel_type_0': 'Matern', 'Matern_0_length_scale': 98514.69338410931, 'Matern_0_nu': 4.043799677232762, 'kernel_type_1': 'Matern', 'Matern_1_length_scale': 27657.84359535279, 'Matern_1_nu': 3.8137626485491465, 'kernel_type_2': 'Matern', 'Matern_2_length_scale': 99021.67315999194, 'Matern_2_nu': 3.407393200010882, 'WhiteKernel_3_noise_level': 66801.01831054635, 'alpha': 0.031062472346451615, 'n_restarts_optimizer': 7}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.03544444647030521, 'n_restarts_optimizer': 10, 'kernel': Matern(length_scale=7.25e+04, nu=3.64) + Matern(length_scale=2.5e+04, nu=4.11) + RationalQuadratic(alpha=804, length_scale=9.96e+04)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-08. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-12-19 17:53:04,037]\u001b[0m Trial 16 finished with value: 49.91763999747879 and parameters: {'n_kernels': 3, 'kernel_type_0': 'Matern', 'Matern_0_length_scale': 72455.101666054, 'Matern_0_nu': 3.6446069027724644, 'kernel_type_1': 'Matern', 'Matern_1_length_scale': 25040.77712417939, 'Matern_1_nu': 4.109579879220222, 'kernel_type_2': 'RationalQuadratic', 'RationalQuadratic_2_length_scale': 99570.08716297068, 'RationalQuadratic_2_alpha': 804.1040980528269, 'WhiteKernel_3_noise_level': 75925.14252745925, 'alpha': 0.03544444647030521, 'n_restarts_optimizer': 10}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.0012661989972729496, 'n_restarts_optimizer': 8, 'kernel': RationalQuadratic(alpha=4.13e+04, length_scale=2.71e+03) + Matern(length_scale=4.36e+04, nu=3.3) + Matern(length_scale=9.71e+04, nu=2.77)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__length_scale is close to the specified lower bound 1e-08. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-12-19 17:55:04,379]\u001b[0m Trial 17 finished with value: 49.99931819406822 and parameters: {'n_kernels': 3, 'kernel_type_0': 'RationalQuadratic', 'RationalQuadratic_0_length_scale': 2706.879296918072, 'RationalQuadratic_0_alpha': 41296.41221101981, 'kernel_type_1': 'Matern', 'Matern_1_length_scale': 43576.496980144766, 'Matern_1_nu': 3.3031630250424016, 'kernel_type_2': 'Matern', 'Matern_2_length_scale': 97104.08995075297, 'Matern_2_nu': 2.770954131503216, 'WhiteKernel_3_noise_level': 23106.93990919988, 'alpha': 0.0012661989972729496, 'n_restarts_optimizer': 8}. Best is trial 0 with value: 48.51528888534959.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.24052398094282287, 'n_restarts_optimizer': 8, 'kernel': Matern(length_scale=9.42e+04, nu=4.65) + Matern(length_scale=3.96e+04, nu=3.31)}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mRuntimeWarning\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(pruner\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39mpruners\u001b[38;5;241m.\u001b[39mSuccessiveHalvingPruner())\n\u001b[1;32m----> 3\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    393\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    395\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis feature will be removed in v4.0.0. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    397\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m     )\n\u001b[1;32m--> 400\u001b[0m \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m show_progress_bar:\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\optuna\\study\\_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    210\u001b[0m     thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 213\u001b[0m     value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[70], line 23\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     20\u001b[0m sampled_indexes \u001b[38;5;241m=\u001b[39m X_train_sampled\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     21\u001b[0m y_train_sampled \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mloc[sampled_indexes]\n\u001b[1;32m---> 23\u001b[0m \u001b[43moptuna_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_sampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     26\u001b[0m verif_pred \u001b[38;5;241m=\u001b[39m optuna_model\u001b[38;5;241m.\u001b[39mpredict(X_verif)\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:286\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_marginal_likelihood(theta, clone_kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# First optimize starting from theta specified in kernel\u001b[39;00m\n\u001b[0;32m    284\u001b[0m optima \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    285\u001b[0m     (\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constrained_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m     )\n\u001b[0;32m    290\u001b[0m ]\n\u001b[0;32m    292\u001b[0m \u001b[38;5;66;03m# Additional runs are performed from log-uniform chosen initial\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;66;03m# theta\u001b[39;00m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:622\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[1;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 622\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[0;32m    630\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\scipy\\optimize\\_minimize.py:696\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    693\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    694\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 696\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    697\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    699\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    700\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:359\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    353\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    356\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    362\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\scipy\\optimize\\_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\scipy\\optimize\\_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 70\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:276\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[1;34m(theta, eval_gradient)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[1;32m--> 276\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:546\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[1;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[0;32m    543\u001b[0m     kernel\u001b[38;5;241m.\u001b[39mtheta \u001b[38;5;241m=\u001b[39m theta\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[1;32m--> 546\u001b[0m     K, K_gradient \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    548\u001b[0m     K \u001b[38;5;241m=\u001b[39m kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train_)\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:843\u001b[0m, in \u001b[0;36mSum.__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m    842\u001b[0m     K1, K1_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk1(X, Y, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 843\u001b[0m     K2, K2_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m K1 \u001b[38;5;241m+\u001b[39m K2, np\u001b[38;5;241m.\u001b[39mdstack((K1_gradient, K2_gradient))\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:1691\u001b[0m, in \u001b[0;36mMatern.__call__\u001b[1;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[0;32m   1689\u001b[0m length_scale \u001b[38;5;241m=\u001b[39m _check_length_scale(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_scale)\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1691\u001b[0m     dists \u001b[38;5;241m=\u001b[39m \u001b[43mpdist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlength_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meuclidean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n",
      "File \u001b[1;32mc:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\scipy\\spatial\\distance.py:2242\u001b[0m, in \u001b[0;36mpdist\u001b[1;34m(X, metric, out, **kwargs)\u001b[0m\n\u001b[0;32m   2240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metric_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2241\u001b[0m     pdist_fn \u001b[38;5;241m=\u001b[39m metric_info\u001b[38;5;241m.\u001b[39mpdist_func\n\u001b[1;32m-> 2242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pdist_fn(X, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2243\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mstr\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2244\u001b[0m     metric_info \u001b[38;5;241m=\u001b[39m _TEST_METRICS\u001b[38;5;241m.\u001b[39mget(mstr, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "study = optuna.create_study(pruner=optuna.pruners.SuccessiveHalvingPruner())\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reconstruct the kernel based on the results from the optuna test.\n",
    "def reconstruct_kernel(encoding):\n",
    "    n_kernels = encoding['n_kernels']\n",
    "    kernels = []\n",
    "    for i in range(n_kernels):\n",
    "        kernel_type = encoding[f'kernel_type_{i}']\n",
    "        length_scale = encoding.get(f'{kernel_type}_{i}_length_scale', None)\n",
    "        nu = encoding.get(f'{kernel_type}_{i}_nu', None)\n",
    "\n",
    "        if kernel_type == 'Matern':\n",
    "            kernel = Matern(length_scale=length_scale, nu=nu)\n",
    "        elif kernel_type == 'RationalQuadratic':\n",
    "            alpha = encoding.get(f'{kernel_type}_{i}_alpha', 1.0)\n",
    "            kernel = RationalQuadratic(length_scale=length_scale, alpha=alpha)\n",
    "        elif kernel_type == 'WhiteKernel':\n",
    "            noise_level = encoding.get(f'{kernel_type}_{i}_noise_level', 1.0)\n",
    "            print(noise_level)\n",
    "            kernel = WhiteKernel(noise_level=noise_level)\n",
    "        # Add more conditions for other kernel types if needed\n",
    "\n",
    "        kernels.append(kernel)\n",
    "\n",
    "    #noise_level = encoding.get(f'WhiteKernel_{n_kernels}_noise_level', 1)\n",
    "    #kernel = WhiteKernel(noise_level=noise_level)\n",
    "    #kernels.append(kernel)\n",
    "\n",
    "    # Sum the individual kernels to get the final composite kernel\n",
    "    if n_kernels == 1:\n",
    "        final_kernel = kernels[0]\n",
    "    else:\n",
    "        final_kernel = Sum(kernels[0], kernels[1])\n",
    "        for j in range(1, n_kernels-1):\n",
    "            final_kernel = Sum(final_kernel, kernels[j+1])\n",
    "    return final_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SANITY CHECK VALUES:\n",
      "Verification RMSE: 16.005811334029733\n",
      "Validation RMSE: 16.326713639930887\n"
     ]
    }
   ],
   "source": [
    "#Check performance with no tuning to ensure performance is improving\n",
    "sanity_check = GaussianProcessRegressor(kernel=RBF())\n",
    "sanity_check.fit(X_train.iloc[0:499], y_train.iloc[0:499])\n",
    "val_pred = sanity_check.predict(X_val)\n",
    "verif_pred = sanity_check.predict(X_verif)\n",
    "sanity_verif_error = mean_squared_error(y_verif,verif_pred,squared=False)\n",
    "sanity_val_error = mean_squared_error(y_val,val_pred,squared=False)\n",
    "print(\"SANITY CHECK VALUES:\")\n",
    "print(\"Verification RMSE:\", sanity_verif_error)\n",
    "print(\"Validation RMSE:\", sanity_val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[43mtrial\u001b[49m\u001b[38;5;241m.\u001b[39mparams\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(params)\n\u001b[0;32m      3\u001b[0m kernel \u001b[38;5;241m=\u001b[39m reconstruct_kernel(params)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trial' is not defined"
     ]
    }
   ],
   "source": [
    "params = trial.params\n",
    "print(params)\n",
    "kernel = reconstruct_kernel(params)\n",
    "print(kernel)\n",
    "gp = GaussianProcessRegressor(kernel=kernel,alpha=params['alpha'], n_restarts_optimizer=params['n_restarts_optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianProcessRegressor(alpha=0.0015488709805414154,\n",
       "                         kernel=Matern(length_scale=7.62e+04, nu=1.82) + Matern(length_scale=2.41e+04, nu=3.87) + WhiteKernel(noise_level=2.56e+04),\n",
       "                         n_restarts_optimizer=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianProcessRegressor</label><div class=\"sk-toggleable__content\"><pre>GaussianProcessRegressor(alpha=0.0015488709805414154,\n",
       "                         kernel=Matern(length_scale=7.62e+04, nu=1.82) + Matern(length_scale=2.41e+04, nu=3.87) + WhiteKernel(noise_level=2.56e+04),\n",
       "                         n_restarts_optimizer=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.0015488709805414154,\n",
       "                         kernel=Matern(length_scale=7.62e+04, nu=1.82) + Matern(length_scale=2.41e+04, nu=3.87) + WhiteKernel(noise_level=2.56e+04),\n",
       "                         n_restarts_optimizer=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.fit(X_train.iloc[0:499], y_train.iloc[0:499])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.678907046098204\n",
      "Difference from sanity check: 11.647806593832684\n"
     ]
    }
   ],
   "source": [
    "val_pred, std_prediction = gp.predict(X_val, return_std=True)\n",
    "error = mean_squared_error(y_val,val_pred,squared=False)\n",
    "print(\"RMSE:\", error)\n",
    "print(\"Difference from sanity check:\", sanity_val_error - error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val R:\n",
      "-0.024127588444852188\n"
     ]
    }
   ],
   "source": [
    "val_r = r2_score(y_val,val_pred)\n",
    "\n",
    "print(\"val R:\")\n",
    "print(val_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "OUTPUT_TEST set to False. If you would like to output final test values set to True and continue running from here",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m OUTPUT_TEST:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOUTPUT_TEST set to False. If you would like to output final test values set to True and continue running from here\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: OUTPUT_TEST set to False. If you would like to output final test values set to True and continue running from here"
     ]
    }
   ],
   "source": [
    "if not OUTPUT_TEST:\n",
    "    raise ValueError(\"OUTPUT_TEST set to False. If you would like to output final test values set to True and continue running from here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"../data/cleaned/test.csv\")\n",
    "y_test = pd.read_csv(\"../data/cleaned/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_test.columns\n",
    "for col in columns:\n",
    "    if '[' in col or ']' in col:\n",
    "        old_name = col\n",
    "        col = col.replace('[', '(')\n",
    "        col = col.replace(']', ')')\n",
    "        \n",
    "        X_test = X_test.rename(columns={old_name:col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = gp.predict(X_test)\n",
    "train_preds = gp.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save test true vals and predictions to csv\n",
    "\n",
    "pred_data = pd.DataFrame(test_preds)\n",
    "pred_filepath = '../data/predictions/GP/test_pred_gp.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)\n",
    "pred_data = pd.DataFrame(y_test)\n",
    "pred_filepath = '../data/predictions/GP/test_true_gp.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)\n",
    "\n",
    "#Save train true vals and predictions to csv\n",
    "\n",
    "pred_data = pd.DataFrame(train_preds)\n",
    "pred_filepath = '../data/predictions/GP/train_pred_gp.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)\n",
    "pred_data = pd.DataFrame(y_train)\n",
    "pred_filepath = '../data/predictions/GP/train_true_gp.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save inputs to csv\n",
    "\n",
    "pred_data = pd.DataFrame(X_train)\n",
    "pred_filepath = '../data/predictions/GP/train_input_gp.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)\n",
    "true_data = pd.DataFrame(X_test)\n",
    "true_filepath = '../data/predictions/GP/test_input_gp.csv'\n",
    "true_data.to_csv(true_filepath, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "4.6359895675101335\n",
      "Test:\n",
      "4.6813758913658905\n",
      "-0.011374792120455002\n"
     ]
    }
   ],
   "source": [
    "#Read in values from csv and calculate RMSE and r values\n",
    "\n",
    "test_pred_data = np.genfromtxt('../data/predictions/GP/test_pred_gp.csv', delimiter=',', filling_values=np.nan)\n",
    "test_true_data = np.genfromtxt('../data/predictions/GP/test_true_gp.csv', delimiter=',', filling_values=np.nan)\n",
    "train_pred_data = np.genfromtxt('../data/predictions/GP/train_pred_gp.csv', delimiter=',', filling_values=np.nan)\n",
    "train_true_data = np.genfromtxt('../data/predictions/GP/train_true_gp.csv', delimiter=',', filling_values=np.nan)\n",
    "\n",
    "test_rmse = mean_squared_error(test_true_data,test_pred_data,squared=False)\n",
    "test_r = r2_score(test_true_data,test_pred_data)\n",
    "\n",
    "train_rmse = mean_squared_error(train_true_data,train_pred_data,squared=False)\n",
    "train_r = r2_score(train_true_data,train_pred_data)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(train_rmse)\n",
    "print('Test:')\n",
    "print(test_rmse)\n",
    "print(test_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent Error: 74.22485943098808\n"
     ]
    }
   ],
   "source": [
    "print(\"percent Error:\", mean_absolute_percentage_error(test_true_data, test_pred_data)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
