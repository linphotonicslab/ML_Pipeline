{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic, Matern, WhiteKernel, RBF\n",
    "from sklearn.gaussian_process.kernels import Sum\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_TEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../data/cleaned/training.csv\")\n",
    "y_train = pd.read_csv(\"../data/cleaned/training_labels.csv\")\n",
    "X_val = pd.read_csv(\"../data/cleaned/validation.csv\")\n",
    "y_val = pd.read_csv(\"../data/cleaned/validation_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_train.columns\n",
    "for col in columns:\n",
    "    if '[' in col or ']' in col:\n",
    "        old_name = col\n",
    "        col = col.replace('[', '(')\n",
    "        col = col.replace(']', ')')\n",
    "        \n",
    "        X_train = X_train.rename(columns={old_name:col})\n",
    "        X_val = X_val.rename(columns={old_name:col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_verif, y_train, y_verif = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_verif = X_verif.reset_index(drop=True)\n",
    "y_verif = y_verif.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_kernel(trial):\n",
    "    kernels = []\n",
    "    n_kernels = trial.suggest_int('n_kernels', 1, 3)\n",
    "    for i in range(n_kernels):\n",
    "        kernel_type = trial.suggest_categorical(f'kernel_type_{i}', [\"Matern\", \"RationalQuadratic\", \"WhiteKernel\"])\n",
    "        if kernel_type == 'RationalQuadratic':\n",
    "            quad_params = {\n",
    "                'length_scale': trial.suggest_float(f'RationalQuadratic_{i}_length_scale', 1e-5, 1e5),\n",
    "                'alpha': trial.suggest_float(f'RationalQuadratic_{i}_alpha', 1e-5, 1e5)\n",
    "            }   \n",
    "            kernel = RationalQuadratic(length_scale=quad_params['length_scale'], alpha=quad_params['alpha'], length_scale_bounds=(1e-8,1e8))\n",
    "        elif kernel_type == 'Matern':\n",
    "            matern_params = {\n",
    "                'length_scale': trial.suggest_float(f'Matern_{i}_length_scale', 1e-5, 1e5),\n",
    "                'nu': trial.suggest_float(f'Matern_{i}_nu', 0.5, 5)\n",
    "            }\n",
    "            kernel = Matern(length_scale=matern_params['length_scale'], nu=matern_params['nu'], length_scale_bounds=(1e-8,1e8))\n",
    "        elif kernel_type == \"WhiteKernel\":\n",
    "            white_noise_params = {\n",
    "                'noise_level': trial.suggest_float(f'WhiteKernel_{i}_noise_level', 1e-5, 1e5),\n",
    "            }\n",
    "            kernel = WhiteKernel(noise_level=white_noise_params['noise_level'])\n",
    "        else:\n",
    "            print(\"WRONG KERNEL NAME FOR:\", kernel_type)\n",
    "            TypeError\n",
    "        kernels.append(kernel)\n",
    "\n",
    "    if len(kernels) == 1:\n",
    "        return kernels[0]\n",
    "    else:\n",
    "        combined_kernel = Sum(kernels[0], kernels[1])\n",
    "        for j in range(1, n_kernels-1):\n",
    "            combined_kernel = Sum(combined_kernel, kernels[j+1])\n",
    "    return combined_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Define the objective function\"\"\"\n",
    "    kernel = define_kernel(trial)\n",
    "    params = {\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 1e3, log=True),\n",
    "        'n_restarts_optimizer': trial.suggest_int('n_restarts_optimizer', 0, 10),\n",
    "    }\n",
    "\n",
    "    params[\"kernel\"] = kernel\n",
    "    print(params)\n",
    "    # Fit the model\n",
    "    #bst = xgb.train(param, dtrain, evals=[(dtest, \"validation\")], callbacks=[pruning_callback])\n",
    "    optuna_model = GaussianProcessRegressor(**params)\n",
    "    #optuna_model.fit(X_train, y_train)\n",
    "    \n",
    "    batch_size = 500\n",
    "\n",
    "    # Take a random sample of the DataFrame\n",
    "    X_train_sampled = X_train.sample(n=batch_size)\n",
    "\n",
    "    # Access the indexes of the sampled rows\n",
    "    sampled_indexes = X_train_sampled.index\n",
    "    y_train_sampled = y_train.loc[sampled_indexes]\n",
    "\n",
    "    optuna_model.fit(X_train_sampled, y_train_sampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    verif_pred = optuna_model.predict(X_verif)\n",
    "    train_pred = optuna_model.predict(X_train_sampled)\n",
    "    verif_loss = mean_squared_error(y_verif,verif_pred,squared=False)\n",
    "    train_loss = mean_squared_error(y_train_sampled,train_pred,squared=False)\n",
    "    #val_loss_array.append(val_loss)\n",
    "    #train_loss_array.append(train_loss)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    error = abs(verif_loss - train_loss) + 2 * train_loss\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-11-30 18:34:17,632]\u001b[0m A new study created in memory with name: no-name-0d87d8c9-0ae4-497b-a1f1-88af119afc17\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.08701801209740515, 'n_restarts_optimizer': 2, 'kernel': WhiteKernel(noise_level=7.92e+04) + Matern(length_scale=7.49e+04, nu=1.82)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-11-30 18:34:49,354]\u001b[0m Trial 0 finished with value: 8.917633049120315 and parameters: {'n_kernels': 2, 'kernel_type_0': 'WhiteKernel', 'WhiteKernel_0_noise_level': 79162.75806060382, 'kernel_type_1': 'Matern', 'Matern_1_length_scale': 74867.98261295247, 'Matern_1_nu': 1.8180868883269663, 'alpha': 0.08701801209740515, 'n_restarts_optimizer': 2}. Best is trial 0 with value: 8.917633049120315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.011002943458429866, 'n_restarts_optimizer': 4, 'kernel': WhiteKernel(noise_level=6.79e+04)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-11-30 18:34:49,948]\u001b[0m Trial 1 finished with value: 38.33262499613891 and parameters: {'n_kernels': 1, 'kernel_type_0': 'WhiteKernel', 'WhiteKernel_0_noise_level': 67949.32089873607, 'alpha': 0.011002943458429866, 'n_restarts_optimizer': 4}. Best is trial 0 with value: 8.917633049120315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.023934356737900807, 'n_restarts_optimizer': 1, 'kernel': WhiteKernel(noise_level=9.07e+04)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-11-30 18:34:50,254]\u001b[0m Trial 2 finished with value: 38.29190347744576 and parameters: {'n_kernels': 1, 'kernel_type_0': 'WhiteKernel', 'WhiteKernel_0_noise_level': 90658.91788837631, 'alpha': 0.023934356737900807, 'n_restarts_optimizer': 1}. Best is trial 0 with value: 8.917633049120315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 41.163692461828404, 'n_restarts_optimizer': 10, 'kernel': WhiteKernel(noise_level=9.98e+04) + WhiteKernel(noise_level=2.02e+04) + RationalQuadratic(alpha=6.69e+04, length_scale=2.22e+04)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-11-30 18:35:30,705]\u001b[0m Trial 3 finished with value: 9.711113792101703 and parameters: {'n_kernels': 3, 'kernel_type_0': 'WhiteKernel', 'WhiteKernel_0_noise_level': 99793.25321575595, 'kernel_type_1': 'WhiteKernel', 'WhiteKernel_1_noise_level': 20172.20164102994, 'kernel_type_2': 'RationalQuadratic', 'RationalQuadratic_2_length_scale': 22232.89559585054, 'RationalQuadratic_2_alpha': 66925.1954428073, 'alpha': 41.163692461828404, 'n_restarts_optimizer': 10}. Best is trial 0 with value: 8.917633049120315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.5906844986177993, 'n_restarts_optimizer': 6, 'kernel': WhiteKernel(noise_level=9.09e+04)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-11-30 18:35:31,439]\u001b[0m Trial 4 finished with value: 38.09848837314606 and parameters: {'n_kernels': 1, 'kernel_type_0': 'WhiteKernel', 'WhiteKernel_0_noise_level': 90890.843576057, 'alpha': 1.5906844986177993, 'n_restarts_optimizer': 6}. Best is trial 0 with value: 8.917633049120315.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value:  8.917633049120315\n",
      "  Params: \n",
      "    n_kernels: 2\n",
      "    kernel_type_0: WhiteKernel\n",
      "    WhiteKernel_0_noise_level: 79162.75806060382\n",
      "    kernel_type_1: Matern\n",
      "    Matern_1_length_scale: 74867.98261295247\n",
      "    Matern_1_nu: 1.8180868883269663\n",
      "    alpha: 0.08701801209740515\n",
      "    n_restarts_optimizer: 2\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "study = optuna.create_study(pruner=optuna.pruners.SuccessiveHalvingPruner())\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_kernel(encoding):\n",
    "    n_kernels = encoding['n_kernels']\n",
    "    kernels = []\n",
    "    for i in range(n_kernels):\n",
    "        kernel_type = encoding[f'kernel_type_{i}']\n",
    "        length_scale = encoding.get(f'{kernel_type}_{i}_length_scale', None)\n",
    "        nu = encoding.get(f'{kernel_type}_{i}_nu', None)\n",
    "\n",
    "        if kernel_type == 'Matern':\n",
    "            kernel = Matern(length_scale=length_scale, nu=nu)\n",
    "        elif kernel_type == 'RationalQuadratic':\n",
    "            alpha = encoding.get(f'{kernel_type}_{i}_alpha', 1.0)\n",
    "            kernel = RationalQuadratic(length_scale=length_scale, alpha=alpha)\n",
    "        elif kernel_type == 'WhiteKernel':\n",
    "            noise_level = encoding.get(f'{kernel_type}_{i}_noise_level', 1.0)\n",
    "            print(noise_level)\n",
    "            kernel = WhiteKernel(noise_level=noise_level)\n",
    "        # Add more conditions for other kernel types if needed\n",
    "\n",
    "        kernels.append(kernel)\n",
    "\n",
    "    # Sum the individual kernels to get the final composite kernel\n",
    "    if len(kernels) == 1:\n",
    "        return kernels[0]\n",
    "    else:\n",
    "        final_kernel = Sum(kernels[0], kernels[1])\n",
    "        for j in range(1, n_kernels-1):\n",
    "            final_kernel = Sum(final_kernel, kernels[j+1])\n",
    "\n",
    "    return final_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nickr\\anaconda3\\envs\\ml_project\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SANITY CHECK VALUES:\n",
      "Verification RMSE: 19.204835218127272\n",
      "Talidation RMSE: 19.094270223829994\n"
     ]
    }
   ],
   "source": [
    "#Check performance with no tuning to ensure performance is improving\n",
    "sanity_check = GaussianProcessRegressor(kernel=RBF())\n",
    "sanity_check.fit(X_train, y_train)\n",
    "val_pred = sanity_check.predict(X_val)\n",
    "verif_pred = sanity_check.predict(X_verif)\n",
    "sanity_verif_error = mean_squared_error(y_verif,verif_pred,squared=False)\n",
    "sanity_val_error = mean_squared_error(y_val,val_pred,squared=False)\n",
    "print(\"SANITY CHECK VALUES:\")\n",
    "print(\"Verification RMSE:\", sanity_verif_error)\n",
    "print(\"Validation RMSE:\", sanity_val_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_kernels': 2, 'kernel_type_0': 'WhiteKernel', 'WhiteKernel_0_noise_level': 79162.75806060382, 'kernel_type_1': 'Matern', 'Matern_1_length_scale': 74867.98261295247, 'Matern_1_nu': 1.8180868883269663, 'alpha': 0.08701801209740515, 'n_restarts_optimizer': 2}\n",
      "79162.75806060382\n",
      "WhiteKernel(noise_level=7.92e+04) + Matern(length_scale=7.49e+04, nu=1.82)\n"
     ]
    }
   ],
   "source": [
    "params = trial.params\n",
    "print(params)\n",
    "kernel = reconstruct_kernel(params)\n",
    "print(kernel)\n",
    "gp = GaussianProcessRegressor(kernel=kernel,alpha=params['alpha'], n_restarts_optimizer=params['n_restarts_optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred, std_prediction = gp.predict(X_val, return_std=True)\n",
    "error = mean_squared_error(y_val,val_pred,squared=False)\n",
    "print(\"RMSE:\", error)\n",
    "print(\"Difference from sanity check:\", sanity_val_error - error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not OUTPUT_TEST:\n",
    "    raise ValueError(\"OUTPUT_TEST set to False. If you would like to output final test values set to True and continue running from here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"../data/cleaned/test.csv\")\n",
    "y_test = pd.read_csv(\"../data/cleaned/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_test.columns\n",
    "for col in columns:\n",
    "    if '[' in col or ']' in col:\n",
    "        old_name = col\n",
    "        col = col.replace('[', '(')\n",
    "        col = col.replace(']', ')')\n",
    "        \n",
    "        X_test = X_test.rename(columns={old_name:col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = gp.predict(X_test)\n",
    "train_preds = gp.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save test true vals and predictions to csv\n",
    "\n",
    "pred_data = pd.DataFrame(test_preds)\n",
    "pred_filepath = '../data/predictions/GP/test_pred_gp.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)\n",
    "pred_data = pd.DataFrame(y_test)\n",
    "pred_filepath = '../data/predictions/GP/test_true_gp.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)\n",
    "\n",
    "#Save train true vals and predictions to csv\n",
    "\n",
    "pred_data = pd.DataFrame(train_preds)\n",
    "pred_filepath = '../data/predictions/GP/train_pred_gp.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)\n",
    "pred_data = pd.DataFrame(y_train)\n",
    "pred_filepath = '../data/predictions/GP/train_true_gp.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save inputs to csv\n",
    "\n",
    "pred_data = pd.DataFrame(X_train)\n",
    "pred_filepath = '../data/predictions/GP/train_input_gp.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)\n",
    "true_data = pd.DataFrame(X_test)\n",
    "true_filepath = '../data/predictions/GP/test_input_gp.csv'\n",
    "true_data.to_csv(true_filepath, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in values from csv and calculate RMSE and r values\n",
    "\n",
    "test_pred_data = np.genfromtxt('../data/predictions/GP/test_pred_gp.csv', delimiter=',', filling_values=np.nan)\n",
    "test_true_data = np.genfromtxt('../data/predictions/GP/test_true_gp.csv', delimiter=',', filling_values=np.nan)\n",
    "train_pred_data = np.genfromtxt('../data/predictions/GP/train_pred_gp.csv', delimiter=',', filling_values=np.nan)\n",
    "train_true_data = np.genfromtxt('../data/predictions/GP/train_true_gp.csv', delimiter=',', filling_values=np.nan)\n",
    "\n",
    "test_rmse = mean_squared_error(test_true_data,test_pred_data,squared=False)\n",
    "test_r = stats.pearsonr(test_true_data,test_pred_data)\n",
    "\n",
    "train_rmse = mean_squared_error(train_true_data,train_pred_data,squared=False)\n",
    "train_r = stats.pearsonr(train_true_data,train_pred_data)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(train_rmse)\n",
    "print('Test:')\n",
    "print(test_rmse)\n",
    "print(test_r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
