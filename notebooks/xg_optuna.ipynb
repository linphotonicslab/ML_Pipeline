{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import  mean_squared_error\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set this value to true if hyperparameter tuning is complete and the test set should be loaded and predicted on\n",
    "OUTPUT_TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the training and validation datasets\n",
    "X_train = pd.read_csv(\"../data/cleaned/training.csv\")\n",
    "y_train = pd.read_csv(\"../data/cleaned/training_labels.csv\")\n",
    "X_val = pd.read_csv(\"../data/cleaned/validation.csv\")\n",
    "y_val = pd.read_csv(\"../data/cleaned/validation_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some columns headers contain '[' or ']' which are not compatable with sklearn. They are change to '(' and ')' respectively.\n",
    "columns = X_train.columns\n",
    "for col in columns:\n",
    "    if '[' in col or ']' in col:\n",
    "        old_name = col\n",
    "        col = col.replace('[', '(')\n",
    "        col = col.replace(']', ')')\n",
    "        \n",
    "        X_train = X_train.rename(columns={old_name:col})\n",
    "        X_val = X_val.rename(columns={old_name:col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting of the training set into a vedrification and training set with a 90/10 split. This verification set is used for optuna hyperparameter tuning.\n",
    "X_train, X_verif, y_train, y_verif = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset the indicies after splitting the dataset\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "X_verif = X_verif.reset_index(drop=True)\n",
    "y_verif = y_verif.reset_index(drop=True)\n",
    "X_val = X_val.reset_index(drop=True)\n",
    "y_val = y_val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check performance with no tuning to ensure performance is improving\n",
    "sanity_check = XGBRegressor()\n",
    "sanity_check.fit(X_train, y_train)\n",
    "val_pred = sanity_check.predict(X_val)\n",
    "verif_pred = sanity_check.predict(X_verif)\n",
    "sanity_verif_error = mean_squared_error(y_verif,verif_pred,squared=False)\n",
    "sanity_val_error = mean_squared_error(y_val,val_pred,squared=False)\n",
    "print(\"SANITY CHECK VALUES:\")\n",
    "print(\"Verification RMSE:\", sanity_verif_error)\n",
    "print(\"Validation RMSE:\", sanity_val_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    #Define the objective function\n",
    "\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
    "        'subsample': trial.suggest_loguniform('subsample', 0.01, 1.0),\n",
    "        'colsample_bytree': trial.suggest_loguniform('colsample_bytree', 0.01, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
    "    }\n",
    "\n",
    "    params[\"tree_method\"] = \"hist\"\n",
    "\n",
    "    # Fit the model\n",
    "    optuna_model = XGBRegressor(**params)\n",
    "    optuna_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    val_pred = optuna_model.predict(X_val)\n",
    "    train_pred = optuna_model.predict(X_train)\n",
    "    val_loss = mean_squared_error(y_val,val_pred,squared=False)\n",
    "    train_loss = mean_squared_error(y_train,train_pred,squared=False)\n",
    "\n",
    "    # Evaluate predictions\n",
    "    error = (val_loss - train_loss) + 2 * train_loss\n",
    "    \n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = optuna.samplers.CmaEsSampler()\n",
    "study = optuna.create_study(sampler=sampler)\n",
    "study.optimize(objective, n_trials=100, timeout=1800)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: \", trial.value)\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = trial.params\n",
    "model = XGBRegressor(**params)\n",
    "print(params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = model.predict(X_val)\n",
    "error = mean_squared_error(y_val,val_pred,squared=False)\n",
    "print(\"RMSE:\", error)\n",
    "print(\"Difference from sanity check:\", sanity_val_error - error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not OUTPUT_TEST:\n",
    "    raise ValueError(\"OUTPUT_TEST set to False. If you would like to output final test values set to True and continue running from here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"../data/cleaned/test.csv\")\n",
    "y_test = pd.read_csv(\"../data/cleaned/test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_test.columns\n",
    "for col in columns:\n",
    "    if '[' in col or ']' in col:\n",
    "        old_name = col\n",
    "        col = col.replace('[', '(')\n",
    "        col = col.replace(']', ')')\n",
    "        \n",
    "        X_test = X_test.rename(columns={old_name:col})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test)\n",
    "train_preds = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save test true vals and predictions to csv\n",
    "\n",
    "pred_data = pd.DataFrame(test_preds)\n",
    "pred_filepath = '../data/predictions/XG/test_pred_xg.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)\n",
    "pred_data = pd.DataFrame(y_test)\n",
    "pred_filepath = '../data/predictions/XG/test_true_xg.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)\n",
    "\n",
    "#Save train true vals and predictions to csv\n",
    "\n",
    "pred_data = pd.DataFrame(train_preds)\n",
    "pred_filepath = '../data/predictions/XG/train_pred_xg.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)\n",
    "pred_data = pd.DataFrame(y_train)\n",
    "pred_filepath = '../data/predictions/XG/train_true_xg.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save inputs to csv\n",
    "\n",
    "pred_data = pd.DataFrame(X_train)\n",
    "pred_filepath = '../data/predictions/XG/train_input_xg.csv'\n",
    "pred_data.to_csv(pred_filepath, index=False, header=False)\n",
    "true_data = pd.DataFrame(X_test)\n",
    "true_filepath = '../data/predictions/XG/test_input_xg.csv'\n",
    "true_data.to_csv(true_filepath, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in values from csv and calculate RMSE and r values\n",
    "\n",
    "test_pred_data = np.genfromtxt('../data/predictions/XG/test_pred_xg.csv', delimiter=',', filling_values=np.nan)\n",
    "test_true_data = np.genfromtxt('../data/predictions/XG/test_true_xg.csv', delimiter=',', filling_values=np.nan)\n",
    "train_pred_data = np.genfromtxt('../data/predictions/XG/train_pred_xg.csv', delimiter=',', filling_values=np.nan)\n",
    "train_true_data = np.genfromtxt('../data/predictions/XG/train_true_xg.csv', delimiter=',', filling_values=np.nan)\n",
    "\n",
    "test_rmse = mean_squared_error(test_true_data,test_pred_data,squared=False)\n",
    "test_r = stats.pearsonr(test_true_data,test_pred_data)\n",
    "\n",
    "train_rmse = mean_squared_error(train_true_data,train_pred_data,squared=False)\n",
    "train_r = stats.pearsonr(train_true_data,train_pred_data)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(train_rmse)\n",
    "print('Test:')\n",
    "print(test_rmse)\n",
    "print(test_r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
